{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85610bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d81831c-e1f9-47a6-b04a-b67b61400376",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_threshold_hsv(roi, hsv_color, threshold):\n",
    "    \"\"\"Apply color thresholding in HSV color space to isolate specific color ranges in the ROI.\"\"\"\n",
    "    lower_bound = np.array([max(0, hsv_color[0] - threshold), max(0, hsv_color[1] - threshold), max(0, hsv_color[2] - threshold)])\n",
    "    upper_bound = np.array([min(180, hsv_color[0] + threshold), min(255, hsv_color[1] + threshold), min(255, hsv_color[2] + threshold)])\n",
    "    mask = cv2.inRange(roi, lower_bound, upper_bound)\n",
    "    return mask\n",
    "\n",
    "def reference_frame(frame, mask_bound, hsv_color_1, hsv_color_2, threshold=15):\n",
    "    x1, y1, x2, y2 = mask_bound\n",
    "    roi = frame[y1:y2, x1:x2]\n",
    "    roi_hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)  # Convert ROI to HSV\n",
    "\n",
    "    # Apply threshold in HSV color space\n",
    "    mask_1 = apply_threshold_hsv(roi_hsv, hsv_color_1, threshold)\n",
    "    roi[mask_1 != 0] = [255, 0, 0]  # Highlight in BGR space for visibility\n",
    "    cluster_dict_1 = find_clusters(mask_1)\n",
    "\n",
    "    mask_2 = apply_threshold_hsv(roi_hsv, hsv_color_2, threshold)\n",
    "    roi[mask_2 != 0] = [0, 0, 255]  # Highlight in BGR space for visibility\n",
    "    cluster_dict_2 = find_clusters(mask_2)\n",
    "\n",
    "    cluster_dict_2 = filter_noise_clusters(cluster_dict_2, 100)\n",
    "\n",
    "    # Convert clusters to np.array for potential performance improvements\n",
    "    for cluster_idx in cluster_dict_1:\n",
    "        cluster_dict_1[cluster_idx] = np.array(cluster_dict_1[cluster_idx])\n",
    "\n",
    "    for cluster_idx in cluster_dict_2:\n",
    "        cluster_dict_2[cluster_idx] = np.array(cluster_dict_2[cluster_idx])\n",
    "\n",
    "    return roi, cluster_dict_1, cluster_dict_2\n",
    "\n",
    "def filter_noise_clusters(cluster_dict, size_threshold):\n",
    "    \"\"\"\n",
    "    Filters clusters based on a minimum size threshold.\n",
    "\n",
    "    Parameters:\n",
    "    - cluster_dict (dict): A dictionary where each key represents a cluster index,\n",
    "      and the value is a list of points belonging to that cluster.\n",
    "    - size_threshold (int): The minimum number of points a cluster must have to be included.\n",
    "\n",
    "    Returns:\n",
    "    - dict: A new dictionary containing only the clusters that meet the size threshold.\n",
    "    \"\"\"\n",
    "    \n",
    "    filtered_clusters = {}\n",
    "    for key, points in cluster_dict.items():\n",
    "        if len(points) > size_threshold:\n",
    "            filtered_clusters[key] = points\n",
    "            \n",
    "    return filtered_clusters\n",
    "\n",
    "def find_clusters(mask):\n",
    "    \"\"\"Find clusters in the mask using DBSCAN.\"\"\"\n",
    "    \n",
    "    y_coord, x_coord = np.where(mask != 0)\n",
    "    if len(y_coord) == 0:\n",
    "        return {}  # Return an empty dict if no points found\n",
    "    \n",
    "    coord_array = np.stack((y_coord, x_coord), axis=-1)\n",
    "    sorted_array = coord_array[coord_array[:, 1].argsort()]\n",
    "    dbscan = DBSCAN(eps=5, min_samples=10)\n",
    "    clusters = dbscan.fit_predict(sorted_array)\n",
    "\n",
    "    cluster_dict = {}\n",
    "    for point, cluster_idx in zip(sorted_array, clusters):\n",
    "        if cluster_idx != -1:\n",
    "            cluster_dict.setdefault(cluster_idx, []).append(point.tolist())\n",
    "            \n",
    "    return cluster_dict\n",
    "\n",
    "\n",
    "def highlight_clusters(frame_roi, cluster_dict, error_keys, color=(0, 0, 255)):\n",
    "    \"\"\"\n",
    "    Highlights specified clusters in a region of interest by changing their pixel colors.\n",
    "\n",
    "    Parameters:\n",
    "    - frame_roi (numpy.ndarray): The region of interest from the frame where clusters are to be highlighted.\n",
    "    - cluster_dict (dict): A dictionary containing clusters with their points. Each key in the dictionary\n",
    "      represents a cluster index, and the value is a list of points (row, column pairs) belonging to that cluster.\n",
    "    - error_keys (list): A list of keys indicating which clusters in the cluster_dict should be highlighted.\n",
    "    - color (tuple): The BGR color value to use for highlighting. Default is red (0, 0, 255).\n",
    "\n",
    "    Returns:\n",
    "    - numpy.ndarray: The modified region of interest with specified clusters highlighted.\n",
    "    \"\"\"\n",
    "    for key in error_keys:\n",
    "        if key in cluster_dict:  # Check if the key exists in the cluster dictionary\n",
    "            for row, col in cluster_dict[key]:\n",
    "                frame_roi[row, col] = color\n",
    "    return frame_roi\n",
    "    \n",
    "\n",
    "white_keys = ['C', 'D', 'E', 'F', 'G', 'A', 'B']\n",
    "black_keys = ['C#', 'D#', 'F#', 'G#', 'A#']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c4b197d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting loop < cv2.VideoCapture 0x7fc3a09073b0>\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "HSV_color_1 = (33, 70, 180)\n",
    "HSV_color_2 = (160, 120, 200)\n",
    "mask_bound = (0, 265, 640, 452)\n",
    "print(\"starting loop\", cap)\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, frame_img = cap.read()\n",
    "\n",
    "    if not success:\n",
    "        print(\"Ignoring empty camera frame.\")\n",
    "        break\n",
    "\n",
    "    roi, cluster_dict_1, cluster_dict_2 = reference_frame(frame_img, mask_bound, HSV_color_1, HSV_color_2, threshold=40)\n",
    "\n",
    "    # Highlight clusters for visual feedback\n",
    "    error_keys_1 = list(cluster_dict_1.keys())  # Simulating detected errors, adjust as needed\n",
    "    error_keys_2 = list(cluster_dict_2.keys())  # Simulating detected errors, adjust as needed\n",
    "    frame_img = highlight_clusters(roi, cluster_dict_1, error_keys_1, color=(0, 255, 0))  # Green for one set\n",
    "    frame_img = highlight_clusters(frame_img, cluster_dict_2, error_keys_2, color=(0, 0, 255))  # Red for another\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', frame_img)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything is done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16ea3a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HSV Value at (942, 736): [161 132 181]\n",
      "HSV Value at (1008, 779): [160 116 198]\n",
      "HSV Value at (1048, 743): [160 114 186]\n",
      "HSV Value at (866, 731): [160 128 180]\n",
      "HSV Value at (788, 723): [161 128 193]\n",
      "HSV Value at (753, 774): [160 118 188]\n",
      "HSV Value at (724, 727): [ 34  74 176]\n",
      "HSV Value at (642, 722): [ 33  74 178]\n",
      "HSV Value at (828, 725): [ 31  75 170]\n",
      "HSV Value at (898, 736): [ 34  74 172]\n",
      "HSV Value at (971, 735): [ 34  70 178]\n",
      "HSV Value at (834, 720): [ 32  73 171]\n",
      "HSV Value at (899, 746): [ 31  65 169]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m, in \u001b[0;36mpick_color\u001b[0;34m(event, x, y, flags, param)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m cap \u001b[38;5;241m=\u001b[39m  cv2\u001b[38;5;241m.\u001b[39mVideoCapture(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpick_color\u001b[39m(event, x, y, flags, param):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m cv2\u001b[38;5;241m.\u001b[39mEVENT_LBUTTONDOWN:\n\u001b[1;32m      8\u001b[0m         pixel \u001b[38;5;241m=\u001b[39m frame_img[y, x]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cap =  cv2.VideoCapture(0)\n",
    "\n",
    "def pick_color(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        pixel = frame_img[y, x]\n",
    "        \n",
    "        # Convert the color of the selected pixel to HSV\n",
    "        hsv = cv2.cvtColor(np.uint8([[pixel]]), cv2.COLOR_BGR2HSV)\n",
    "        hsv_value = hsv[0][0]\n",
    "        print(\"HSV Value at ({}, {}): {}\".format(x, y, hsv_value))\n",
    "\n",
    "\n",
    "if cap.isOpened():\n",
    "    success, frame_img = cap.read()\n",
    "    cv2.namedWindow('image')\n",
    "    cv2.setMouseCallback('image', pick_color)\n",
    "\n",
    "    # Display the image and wait for a key press\n",
    "    cv2.imshow('image', frame_img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print('no camera')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "c147",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
