{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b3538e2-d5ea-4766-82b9-e627a407cafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import math as m\n",
    "import mediapipe as mp\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ee57f4d-9678-4620-b1ef-795279831aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initilize medipipe selfie segmentation class.\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_holistic = mp.solutions.holistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dc2a353-925c-456e-9dbc-69dd45a6d640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findDistance(x1, y1, x2, y2):\n",
    "    dist = m.sqrt((x2-x1)**2+(y2-y1)**2)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ac082ad-f4d0-43ae-87d5-8c5abc691979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate angle.\n",
    "def findAngle(x1, y1, x2, y2):\n",
    "    theta = m.acos((y2 -y1)*(-y1) / (m.sqrt((x2 - x1)**2 + (y2 - y1)**2) * y1))\n",
    "    degree = int(180/m.pi)*theta\n",
    "    return degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c47f0f02-4d0c-47f0-b871-95222359e3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate angle of arm\n",
    "def findAngleArm(P1_x, P1_y, P2_x, P2_y, P3_x, P3_y):\n",
    "    P12 = m.sqrt((P1_x - P2_x)**2 + (P1_y - P2_y)**2)\n",
    "    P13 = m.sqrt((P1_x - P3_x)**2 + (P1_y - P3_y)**2)\n",
    "    P23 = m.sqrt((P2_x - P3_x)**2 + (P2_y - P3_y)**2)\n",
    "    theta = m.acos((P12**2 + P23**2 - P13**2) / (2 * P12 * P23))\n",
    "    degree = int(180/m.pi)*theta\n",
    "    return degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8510c2fb-2b28-4234-a209-9206057992ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_left_right(hand_x_cord, hip_x_cord):\n",
    "    diff = hand_x_cord - hip_x_cord\n",
    "    if diff < 0:\n",
    "        # print(\"left_facing\")\n",
    "        return \"left\"\n",
    "    else:\n",
    "        # print(\"right_facing\")\n",
    "        return \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4128531-ff5d-4452-bf9f-533a174845d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sendWarning(x):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "faee9047-6b65-4d5a-90f5-3c0de5db0369",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "# Font type.\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    " \n",
    "# Colors.\n",
    "blue = (255, 127, 0)\n",
    "red = (50, 50, 255)\n",
    "green = (127, 255, 0)\n",
    "dark_blue = (127, 20, 0)\n",
    "light_green = (127, 233, 100)\n",
    "yellow = (0, 255, 255)\n",
    "pink = (255, 0, 255)\n",
    " \n",
    "# Initialize mediapipe pose class.\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79311287-fdef-4b83-9780-74c28fedec07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import paho.mqtt.client as mqtt\n",
    "import numpy as np\n",
    "\n",
    "# 0. define callbacks - functions that run when events happen.\n",
    "# The callback for when the client receives a CONNACK response from the server.\n",
    "def on_connect(client, userdata, flags, rc):\n",
    "    print(\"Connection returned result: \"+str(rc))\n",
    "    # Subscribing in on_connect() means that if we lose the connection and\n",
    "    # reconnect then subscriptions will be renewed.\n",
    "    # client.subscribe(\"ece180d/test\")\n",
    "\n",
    "def on_disconnect(client, userdata, rc):\n",
    "    if rc != 0:\n",
    "        print('Unexpected Disconnect')\n",
    "    else:\n",
    "        print('Expected Disconnect')\n",
    "    # The default message callback.\n",
    "    # (wonâ€™t be used if only publishing, but can still exist)\n",
    "\n",
    "def on_message(client, userdata, message):\n",
    "    print('Received message: \"' + str(message.payload) + '\" on topic \"' +\n",
    "    message.topic + '\" with QoS ' + str(message.qos))\n",
    "    \n",
    "# # 1. create a client instance.\n",
    "# client = mqtt.Client()\n",
    "\n",
    "# # add additional client options (security, certifications, etc.)\n",
    "# # many default options should be good to start off.\n",
    "# # add callbacks to client.\n",
    "# client.on_connect = on_connect\n",
    "# client.on_disconnect = on_disconnect\n",
    "# client.on_message = on_message\n",
    "\n",
    "# # 2. connect to a broker using one of the connect*() functions.\n",
    "# client.connect_async('test.mosquitto.org')\n",
    "\n",
    "# 3. call one of the loop*() functions to maintain network traffic flow with the broker.\n",
    "# client.loop_start()\n",
    "\n",
    "# # 4. use subscribe() to subscribe to a topic and receive messages.\n",
    "# # 5. use publish() to publish messages to the broker.\n",
    "# # payload must be a string, bytearray, int, float or None.\n",
    "# for i in range(10):\n",
    "#     client.publish('ece180d/test', float(np.random.random(1)), qos=1)\n",
    "    \n",
    "# # 6. use disconnect() to disconnect from the broker.\n",
    "# client.loop_stop()\n",
    "# client.disconnect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44f4beea-2ec7-4f31-ab97-ef361e678947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection returned result: 0\n",
      "Ignoring empty camera frame.\n",
      "Expected Disconnect\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. create a client instance.\n",
    "client = mqtt.Client()\n",
    "\n",
    "# add additional client options (security, certifications, etc.)\n",
    "# many default options should be good to start off.\n",
    "# add callbacks to client.\n",
    "client.on_connect = on_connect\n",
    "client.on_disconnect = on_disconnect\n",
    "client.on_message = on_message\n",
    "\n",
    "# 2. connect to a broker using one of the connect*() functions.\n",
    "client.connect_async('test.mosquitto.org')\n",
    "\n",
    "client.loop_start()\n",
    "cap = cv2.VideoCapture('C:\\\\Users\\\\17147\\\\Desktop\\\\College\\\\180DA\\\\input.mp4')\n",
    "# cap = cv2.VideoCapture('C:\\\\Users\\\\17147\\\\Desktop\\\\College\\\\180DA\\\\sample1.mp4')\n",
    "# cap =  cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "\n",
    "# start = time.time()\n",
    "while cap.isOpened():\n",
    "    w = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "    h = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "    \n",
    "    # Capture frames.\n",
    "    success, frame = cap.read()\n",
    "\n",
    "    if not success:\n",
    "        print(\"Ignoring empty camera frame.\")\n",
    "        break\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Convert the BGR image to RGB.\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # To improve performance\n",
    "    image.flags.writeable = False\n",
    "\n",
    "    # Process the image.\n",
    "    keypoints = pose.process(image)\n",
    "\n",
    "    # Convert the image back to BGR.\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Use lm and lmPose as representative of the following methods.\n",
    "    lm = keypoints.pose_landmarks\n",
    "    lmPose = mp_pose.PoseLandmark\n",
    "\n",
    "    \"\"\"Getting the facing direction\"\"\"\n",
    "    if count == 0:\n",
    "        l_hip_x = int(lm.landmark[lmPose.LEFT_HIP].x * w)\n",
    "        l_wrist_x = int(lm.landmark[lmPose.LEFT_WRIST].x * w)\n",
    "        facing = check_left_right(l_wrist_x, l_hip_x)\n",
    "        count += 1\n",
    "    \n",
    "    \"\"\"Acquire the landmark coordinates depending on facing direction\"\"\"\n",
    "    if facing == \"left\":\n",
    "        # print(\"left\")\n",
    "        # Left shoulder.\n",
    "        l_shldr_x = int(lm.landmark[lmPose.LEFT_SHOULDER].x * w)\n",
    "        l_shldr_y = int(lm.landmark[lmPose.LEFT_SHOULDER].y * h)\n",
    "        # Right shoulder\n",
    "        r_shldr_x = int(lm.landmark[lmPose.RIGHT_SHOULDER].x * w)\n",
    "        r_shldr_y = int(lm.landmark[lmPose.RIGHT_SHOULDER].y * h)\n",
    "        # Left ear.\n",
    "        l_ear_x = int(lm.landmark[lmPose.LEFT_EAR].x * w)\n",
    "        l_ear_y = int(lm.landmark[lmPose.LEFT_EAR].y * h)\n",
    "        # Left hip.\n",
    "        l_hip_y = int(lm.landmark[lmPose.LEFT_HIP].y * h)\n",
    "        l_hip_x = int(lm.landmark[lmPose.LEFT_HIP].x * w)\n",
    "        # Left elbow\n",
    "        l_elbw_y = int(lm.landmark[lmPose.LEFT_ELBOW].y * h)\n",
    "        l_elbw_x = int(lm.landmark[lmPose.LEFT_ELBOW].x * w)\n",
    "        # Left wrist\n",
    "        l_wrst_y = int(lm.landmark[lmPose.LEFT_WRIST].y * h)\n",
    "        l_wrst_x = int(lm.landmark[lmPose.LEFT_WRIST].x * w)\n",
    "\n",
    "\n",
    "        # To improve performance\n",
    "        image.flags.writeable = True\n",
    "\n",
    "        cv2.circle(image, (l_shldr_x, l_shldr_y), 7, yellow, -1)\n",
    "        cv2.circle(image, (l_ear_x, l_ear_y), 7, yellow, -1)\n",
    "        cv2.circle(image, (l_shldr_x, l_shldr_y - 100), 7, yellow, -1)\n",
    "        cv2.circle(image, (r_shldr_x, r_shldr_y), 7, pink, -1)\n",
    "        cv2.circle(image, (l_hip_x, l_hip_y), 7, yellow, -1)\n",
    "        cv2.circle(image, (l_hip_x, l_hip_y - 100), 7, yellow, -1)\n",
    "        cv2.circle(image, (l_elbw_x, l_elbw_y), 7, yellow, -1)\n",
    "        cv2.circle(image, (l_wrst_x, l_wrst_y), 7, yellow, -1)\n",
    "\n",
    "        # Calculate angles.\n",
    "        neck_inclination = findAngle(l_shldr_x, l_shldr_y, l_ear_x, l_ear_y)\n",
    "        torso_inclination = findAngle(l_hip_x, l_hip_y, l_shldr_x, l_shldr_y)\n",
    "        arm_inclination = findAngleArm(l_shldr_x, l_shldr_y, l_elbw_x, l_elbw_y, l_wrst_x, l_wrst_y)\n",
    "\n",
    "        \"\"\"Put text, Posture and angle inclination.\"\"\"\n",
    "        # Text string for display.\n",
    "        angle_text_string = 'Neck : ' + str(int(neck_inclination)) + '  Torso : ' + str(int(torso_inclination))\n",
    "\n",
    "        # Determine whether good posture or bad posture.\n",
    "        if neck_inclination < 40 and torso_inclination < 10:\n",
    "    \n",
    "            cv2.putText(image, angle_text_string, (10, 30), font, 0.9, light_green, 2)\n",
    "            cv2.putText(image, str(int(neck_inclination)), (l_shldr_x + 10, l_shldr_y), font, 0.9, light_green, 2)\n",
    "            cv2.putText(image, str(int(torso_inclination)), (l_hip_x + 10, l_hip_y), font, 0.9, light_green, 2)\n",
    "            cv2.putText(image, str(int(arm_inclination)), (l_elbw_x + 10, l_elbw_y), font, 0.9, light_green, 2)\n",
    "    \n",
    "            # Join landmarks.\n",
    "            cv2.line(image, (l_shldr_x, l_shldr_y), (l_ear_x, l_ear_y), green, 4)\n",
    "            cv2.line(image, (l_shldr_x, l_shldr_y), (l_shldr_x, l_shldr_y - 100), green, 4)\n",
    "            cv2.line(image, (l_hip_x, l_hip_y), (l_shldr_x, l_shldr_y), green, 4)\n",
    "            cv2.line(image, (l_hip_x, l_hip_y), (l_hip_x, l_hip_y - 100), green, 4)\n",
    "            cv2.line(image, (l_shldr_x, l_shldr_y), (l_elbw_x, l_elbw_y), green, 4)\n",
    "            cv2.line(image, (l_elbw_x, l_elbw_y), (l_wrst_x, l_wrst_y), green, 4)\n",
    "    \n",
    "        else:\n",
    "    \n",
    "            cv2.putText(image, angle_text_string, (10, 30), font, 0.9, red, 2)\n",
    "            cv2.putText(image, str(int(neck_inclination)), (l_shldr_x + 10, l_shldr_y), font, 0.9, red, 2)\n",
    "            cv2.putText(image, str(int(torso_inclination)), (l_hip_x + 10, l_hip_y), font, 0.9, red, 2)\n",
    "            cv2.putText(image, str(int(arm_inclination)), (l_elbw_x + 10, l_elbw_y), font, 0.9, red, 2)\n",
    "    \n",
    "            # Join landmarks.\n",
    "            cv2.line(image, (l_shldr_x, l_shldr_y), (l_ear_x, l_ear_y), red, 4)\n",
    "            cv2.line(image, (l_shldr_x, l_shldr_y), (l_shldr_x, l_shldr_y - 100), red, 4)\n",
    "            cv2.line(image, (l_hip_x, l_hip_y), (l_shldr_x, l_shldr_y), red, 4)\n",
    "            cv2.line(image, (l_hip_x, l_hip_y), (l_hip_x, l_hip_y - 100), red, 4)\n",
    "            cv2.line(image, (l_shldr_x, l_shldr_y), (l_elbw_x, l_elbw_y), red, 4)\n",
    "            cv2.line(image, (l_elbw_x, l_elbw_y), (l_wrst_x, l_wrst_y), red, 4)\n",
    "        \n",
    "\n",
    "    elif facing == \"right\":\n",
    "        # print(\"right\")\n",
    "        l_shldr_x = int(lm.landmark[lmPose.LEFT_SHOULDER].x * w)\n",
    "        l_shldr_y = int(lm.landmark[lmPose.LEFT_SHOULDER].y * h)\n",
    "        # Right shoulder\n",
    "        r_shldr_x = int(lm.landmark[lmPose.RIGHT_SHOULDER].x * w)\n",
    "        r_shldr_y = int(lm.landmark[lmPose.RIGHT_SHOULDER].y * h)\n",
    "        # Right ear\n",
    "        r_ear_x = int(lm.landmark[lmPose.RIGHT_EAR].x * w)\n",
    "        r_ear_y = int(lm.landmark[lmPose.RIGHT_EAR].y * h)\n",
    "        # Right hip\n",
    "        r_hip_y = int(lm.landmark[lmPose.RIGHT_HIP].y * h)\n",
    "        r_hip_x = int(lm.landmark[lmPose.RIGHT_HIP].x * w)\n",
    "        # Right elbow\n",
    "        r_elbw_y = int(lm.landmark[lmPose.RIGHT_ELBOW].y * h)\n",
    "        r_elbw_x = int(lm.landmark[lmPose.RIGHT_ELBOW].x * w)\n",
    "        # Right wrist\n",
    "        r_wrst_y = int(lm.landmark[lmPose.RIGHT_WRIST].y * h)\n",
    "        r_wrst_x = int(lm.landmark[lmPose.RIGHT_WRIST].x * w)\n",
    "\n",
    "        cv2.circle(image, (r_shldr_x, r_shldr_y), 7, yellow, -1)\n",
    "        cv2.circle(image, (r_shldr_x, r_shldr_y - 100), 7, yellow, -1)\n",
    "        cv2.circle(image, (r_ear_x, r_ear_y), 7, yellow, -1)\n",
    "        cv2.circle(image, (l_shldr_x, l_shldr_y), 7, pink, -1)\n",
    "        cv2.circle(image, (r_hip_x, r_hip_y), 7, yellow, -1)\n",
    "        cv2.circle(image, (r_hip_x, r_hip_y - 100), 7, yellow, -1)\n",
    "        cv2.circle(image, (r_elbw_x, r_elbw_y), 7, yellow, -1)\n",
    "        cv2.circle(image, (r_wrst_x, r_wrst_y), 7, yellow, -1)\n",
    "\n",
    "        # Calculate angles.\n",
    "        neck_inclination = findAngle(r_shldr_x, r_shldr_y, r_ear_x, r_ear_y)\n",
    "        torso_inclination = findAngle(r_hip_x, r_hip_y, r_shldr_x, r_shldr_y)\n",
    "        arm_inclination = findAngleArm(r_shldr_x, r_shldr_y, r_elbw_x, r_elbw_y, r_wrst_x, r_wrst_y)\n",
    "    \n",
    "        \"\"\"Put text, Posture and angle inclination.\"\"\"\n",
    "        # Text string for display.\n",
    "        angle_text_string = 'Neck : ' + str(int(neck_inclination)) + '  Torso : ' + str(int(torso_inclination))\n",
    "\n",
    "        # Determine whether good posture or bad posture.\n",
    "        if neck_inclination < 40 and torso_inclination < 10:\n",
    "    \n",
    "            cv2.putText(image, angle_text_string, (10, 30), font, 0.9, light_green, 2)\n",
    "            cv2.putText(image, str(int(neck_inclination)), (r_shldr_x + 10, r_shldr_y), font, 0.9, light_green, 2)\n",
    "            cv2.putText(image, str(int(torso_inclination)), (r_hip_x + 10, r_hip_y), font, 0.9, light_green, 2)\n",
    "            cv2.putText(image, str(int(arm_inclination)), (r_elbw_x + 10, r_elbw_y), font, 0.9, light_green, 2)\n",
    "    \n",
    "            # Join landmarks.\n",
    "            cv2.line(image, (r_shldr_x, r_shldr_y), (r_ear_x, r_ear_y), green, 4)\n",
    "            cv2.line(image, (r_shldr_x, r_shldr_y), (r_shldr_x, r_shldr_y - 100), green, 4)\n",
    "            cv2.line(image, (r_hip_x, r_hip_y), (r_shldr_x, r_shldr_y), green, 4)\n",
    "            cv2.line(image, (r_hip_x, r_hip_y), (r_hip_x, r_hip_y - 100), green, 4)\n",
    "            cv2.line(image, (r_shldr_x, r_shldr_y), (r_elbw_x, r_elbw_y), green, 4)\n",
    "            cv2.line(image, (r_elbw_x, r_elbw_y), (r_wrst_x, r_wrst_y), green, 4)\n",
    "    \n",
    "        else:\n",
    "    \n",
    "            cv2.putText(image, angle_text_string, (10, 30), font, 0.9, red, 2)\n",
    "            cv2.putText(image, str(int(neck_inclination)), (r_shldr_x + 10, r_shldr_y), font, 0.9, red, 2)\n",
    "            cv2.putText(image, str(int(torso_inclination)), (r_hip_x + 10, r_hip_y), font, 0.9, red, 2)\n",
    "            cv2.putText(image, str(int(arm_inclination)), (r_elbw_x + 10, r_elbw_y), font, 0.9, red, 2)\n",
    "    \n",
    "            # Join landmarks.\n",
    "            cv2.line(image, (r_shldr_x, r_shldr_y), (r_ear_x, r_ear_y), red, 4)\n",
    "            cv2.line(image, (r_shldr_x, r_shldr_y), (r_shldr_x, r_shldr_y - 100), red, 4)\n",
    "            cv2.line(image, (r_hip_x, r_hip_y), (r_shldr_x, r_shldr_y), red, 4)\n",
    "            cv2.line(image, (r_hip_x, r_hip_y), (r_hip_x, r_hip_y - 100), red, 4)\n",
    "            cv2.line(image, (r_shldr_x, r_shldr_y), (r_elbw_x, r_elbw_y), red, 4)\n",
    "            cv2.line(image, (r_elbw_x, r_elbw_y), (r_wrst_x, r_wrst_y), red, 4)\n",
    "    \n",
    "    client.publish('your_topic', int(neck_inclination), qos=1)\n",
    "    cv2.imshow('Raw Webcam Feed', image)\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "    if cv2.getWindowProperty('Raw Webcam Feed', cv2.WND_PROP_VISIBLE) < 1:\n",
    "        break\n",
    "    \n",
    "# end = time.time()\n",
    "# print(end - start)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "client.loop_stop()\n",
    "client.disconnect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10393f8f-e5db-45e8-ae84-8be6763266f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602111b1-454b-4a0b-949c-1594c3d66529",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "180DA",
   "language": "python",
   "name": "180da"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
