{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e73729d8-4a4e-4fb7-b043-714b864bf5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "\n",
    "# cap =  cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "# ref_img = False \n",
    "\n",
    "# while cap.isOpened():\n",
    "    \n",
    "#     success, frame_img = cap.read()\n",
    "#     # frame = cv2.rotate(frame, cv2.ROTATE_180)\n",
    "\n",
    "#     if not success:\n",
    "#         print(\"Ignoring empty camera frame.\")\n",
    "#         break\n",
    "\n",
    "#     if not ref_img:    \n",
    "#         cv2.imshow('Pressed Key Frame', frame_img)\n",
    "        \n",
    "#         if cv2.waitKey(1) & 0xFF == ord('s'):\n",
    "#             break\n",
    "\n",
    "#     cv2.waitKey(1)\n",
    "#     if cv2.getWindowProperty('Pressed Key Frame', cv2.WND_PROP_VISIBLE) < 1:\n",
    "#         break\n",
    "    \n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cdd970b-75d8-4415-b637-b129fe93d62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize blank images for color exploration and selection\n",
    "# color_explore = np.zeros((150, 150, 3), dtype=np.uint8)\n",
    "# color_selected = np.zeros((150, 150, 3), dtype=np.uint8)\n",
    "\n",
    "# # Mouse callback function for showing color under cursor and selected color\n",
    "# def show_color(event, x, y, flags, param):\n",
    "    \n",
    "#     # Extract color components from the image at cursor position\n",
    "#     B, G, R = img[y, x]\n",
    "\n",
    "#     # Update color_explore with the color under cursor\n",
    "#     color_explore[:] = (B, G, R)\n",
    "\n",
    "#     # If left mouse button pressed, update color_selected and print the color values\n",
    "#     if event == cv2.EVENT_LBUTTONDOWN:\n",
    "#         color_selected[:] = (B, G, R)\n",
    "#         black = (B, G, R)\n",
    "#         print(black)\n",
    "\n",
    "# # Create windows for color exploration and selected color display\n",
    "# cv2.namedWindow('color_explore')\n",
    "# cv2.resizeWindow('color_explore', 50, 50)\n",
    "\n",
    "# cv2.namedWindow('color_selected')\n",
    "# cv2.resizeWindow('color_selected', 50, 50)\n",
    "\n",
    "# # Create window for displaying the sample image\n",
    "# cv2.namedWindow('image')\n",
    "\n",
    "# # Path to the sample image\n",
    "# img = frame_img\n",
    "\n",
    "# # Assign the mouse callback function to the 'image' window\n",
    "# cv2.setMouseCallback('image', show_color)\n",
    "\n",
    "# # Main loop for live update of the color exploration and selection\n",
    "# while True:\n",
    "#     cv2.imshow('image', img)\n",
    "#     cv2.imshow('color_explore', color_explore)\n",
    "#     cv2.imshow('color_selected', color_selected)\n",
    "\n",
    "#     # Break the loop if 'Esc' key is pressed\n",
    "#     if cv2.waitKey(1) & 0xFF == 27:\n",
    "#         break\n",
    "\n",
    "# # Clean up windows\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d81831c-e1f9-47a6-b04a-b67b61400376",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "import time\n",
    "\n",
    "\n",
    "# create hex_color_picker\n",
    "\n",
    "def hex_to_bgr(hex_color):\n",
    "    hex_color = hex_color.lstrip('#')\n",
    "    lv = len(hex_color)\n",
    "    return tuple(int(hex_color[i:i + lv // 3], 16) for i in range(0, lv, lv // 3))[::-1]\n",
    "\n",
    "# def apply_threshold(roi, bgr_color, threshold):\n",
    "#     \"\"\"Apply color thresholding to isolate specific color ranges in the ROI.\"\"\"\n",
    "    \n",
    "#     lower_bound = np.array([max(0, bgr_color[0] - threshold), max(0, bgr_color[1] - threshold), max(0, bgr_color[2] - threshold)])\n",
    "#     upper_bound = np.array([min(255, bgr_color[0] + threshold), min(255, bgr_color[1] + threshold), min(255, bgr_color[2] + threshold)])\n",
    "#     mask = cv2.inRange(roi, lower_bound, upper_bound)\n",
    "    \n",
    "#     return mask\n",
    "\n",
    "def apply_threshold_hsv(roi, hsv_color, threshold):\n",
    "    \"\"\"Apply color thresholding in HSV color space to isolate specific color ranges in the ROI.\"\"\"\n",
    "    \n",
    "    lower_bound = np.array([max(0, hsv_color[0] - threshold), max(0, hsv_color[1] - threshold), max(0, hsv_color[2] - threshold)])\n",
    "    upper_bound = np.array([min(180, hsv_color[0] + threshold), min(255, hsv_color[1] + threshold), min(255, hsv_color[2] + threshold)])\n",
    "    mask = cv2.inRange(roi, lower_bound, upper_bound)\n",
    "    return mask\n",
    "\n",
    "def find_clusters(mask):\n",
    "    \"\"\"Find clusters in the mask using DBSCAN.\"\"\"\n",
    "    \n",
    "    y_coord, x_coord = np.where(mask != 0)\n",
    "    if len(y_coord) == 0:\n",
    "        return {}  # Return an empty dict if no points found\n",
    "    \n",
    "    coord_array = np.stack((y_coord, x_coord), axis=-1)\n",
    "    sorted_array = coord_array[coord_array[:, 1].argsort()]\n",
    "    dbscan = DBSCAN(eps=5, min_samples=10)\n",
    "    clusters = dbscan.fit_predict(sorted_array)\n",
    "\n",
    "    cluster_dict = {}\n",
    "    for point, cluster_idx in zip(sorted_array, clusters):\n",
    "        if cluster_idx != -1:\n",
    "            cluster_dict.setdefault(cluster_idx, []).append(point.tolist())\n",
    "            \n",
    "    return cluster_dict\n",
    "\n",
    "def filter_noise_clusters(cluster_dict, size_threshold):\n",
    "    \"\"\"\n",
    "    Filters clusters based on a minimum size threshold.\n",
    "\n",
    "    Parameters:\n",
    "    - cluster_dict (dict): A dictionary where each key represents a cluster index,\n",
    "      and the value is a list of points belonging to that cluster.\n",
    "    - size_threshold (int): The minimum number of points a cluster must have to be included.\n",
    "\n",
    "    Returns:\n",
    "    - dict: A new dictionary containing only the clusters that meet the size threshold.\n",
    "    \"\"\"\n",
    "    \n",
    "    filtered_clusters = {}\n",
    "    for key, points in cluster_dict.items():\n",
    "        if len(points) > size_threshold:\n",
    "            filtered_clusters[key] = points\n",
    "            \n",
    "    return filtered_clusters\n",
    "\n",
    "def generate_error_bounds_for_clusters(cluster_dict_black, cluster_dict_white, initial_threshold=5):\n",
    "    \"\"\"\n",
    "    Generates error bounds for black and white clusters based on their counts and an initial threshold.\n",
    "\n",
    "    Parameters:\n",
    "    - cluster_dict_black (dict): The black clusters dictionary.\n",
    "    - cluster_dict_white (dict): The white clusters dictionary.\n",
    "    - initial_threshold (int): The initial threshold for error calculation.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: Contains two tuples for black and white error bounds, each with a list for lower and upper bounds.\n",
    "    \"\"\"\n",
    "    error_lower_bound_black = [initial_threshold for _ in range(len(cluster_dict_black))]\n",
    "    error_upper_bound_black = [initial_threshold + 15 for _ in range(len(cluster_dict_black))]\n",
    "    \n",
    "    error_lower_bound_white = [initial_threshold for _ in range(len(cluster_dict_white))]\n",
    "    error_upper_bound_white = [initial_threshold + 12 for _ in range(len(cluster_dict_white))]\n",
    "\n",
    "    black_error_bounds = (error_lower_bound_black, error_upper_bound_black)\n",
    "    white_error_bounds = (error_lower_bound_white, error_upper_bound_white)\n",
    "    \n",
    "    return black_error_bounds, white_error_bounds\n",
    "\n",
    "\n",
    "def calibrate_error_bounds(error_keys, error_bounds):\n",
    "    \"\"\"\n",
    "    Adjusts error bounds based on the presence of keys in the error_keys list. If error_keys is not empty,\n",
    "    increments the bounds for those keys. Otherwise, indicates that calibration is done.\n",
    "\n",
    "    Parameters:\n",
    "    - error_keys (list): A list of indices corresponding to clusters that met error criteria.\n",
    "    - error_bounds (tuple): A tuple containing two lists (error_lower_bound, error_upper_bound) representing the current error bounds for filtering.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: The updated error_bounds tuple after adjustment.\n",
    "    \"\"\"\n",
    "    error_lower_bound, error_upper_bound = error_bounds\n",
    "    if error_keys:\n",
    "        for _, value in enumerate(error_keys):\n",
    "            error_lower_bound[value] += 1\n",
    "            error_upper_bound[value] += 1\n",
    "        updated_bounds = (error_lower_bound, error_upper_bound)\n",
    "    else:\n",
    "        print(\"calibration_done:\", error_lower_bound, error_upper_bound)\n",
    "        # each value in error_lower_bound + something to notget other keys  \n",
    "        updated_bounds = error_bounds  # No change if calibration done\n",
    "\n",
    "    return updated_bounds\n",
    "\n",
    "def filter_keys(cluster_dict, roi, inf_roi, error_bounds):\n",
    "    \"\"\"\n",
    "    Calculates error percentages for clusters and filters keys based on error bounds.\n",
    "\n",
    "    Parameters:\n",
    "    - cluster_dict (dict): Clusters to analyze, where each key is a cluster index, and the value is a list of points.\n",
    "    - roi (numpy.ndarray): The reference region of interest from the original frame.\n",
    "    - inf_roi (numpy.ndarray): The inference region of interest from the compared frame.\n",
    "    - error_bounds (tuple): A tuple containing two lists, the first for lower bounds and the \n",
    "      second for upper bounds of error percentages for filtering. Each list's length should match the number of clusters.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: (error_keys, error_percentages)\n",
    "        - error_keys (list): The keys of clusters that fall within the specified error bounds.\n",
    "        - error_percentages (list): The error percentages of all clusters.\n",
    "    \"\"\"\n",
    "    error_keys = []\n",
    "    error_percentages = []\n",
    "    error_lower_bound, error_upper_bound = error_bounds\n",
    "\n",
    "    for index, (key, cluster) in enumerate(cluster_dict.items()):\n",
    "        error_count = sum(1 for row_ref, col_ref in cluster if not np.array_equal(roi[row_ref, col_ref], inf_roi[row_ref, col_ref]))\n",
    "        total_comparisons = len(cluster)\n",
    "\n",
    "        error_percentage = (error_count / total_comparisons) * 100 if total_comparisons > 0 else 0\n",
    "        error_percentages.append(error_percentage)\n",
    "\n",
    "        if total_comparisons > 0 and error_lower_bound[index] < error_percentage < error_upper_bound[index]:\n",
    "            error_keys.append(key)\n",
    "    return error_keys\n",
    "\n",
    "def reference_frame(frame, mask_bound, hsv_color_1, hsv_color_2, threshold=40):\n",
    "    x1, y1, x2, y2 = mask_bound\n",
    "    roi = frame[y1:y2, x1:x2]\n",
    "    roi_hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # black\n",
    "    mask_1 = apply_threshold_hsv(roi_hsv, hsv_color_1, threshold)\n",
    "    roi[mask_1 != 0] = [255, 0, 0]\n",
    "    cluster_dict_1 = find_clusters(mask_1)\n",
    "\n",
    "    # white\n",
    "    mask_2 = apply_threshold_hsv(roi_hsv, hsv_color_2, threshold)\n",
    "    roi[mask_2 != 0] = [255, 0, 255]\n",
    "    cluster_dict_2 = find_clusters(mask_2)\n",
    "\n",
    "    # cluster_dict_1 = filter_noise_clusters(cluster_dict_1, 100)\n",
    "    cluster_dict_2 = filter_noise_clusters(cluster_dict_2, 100)\n",
    "\n",
    "    ###### Check if this improves the latency otherwise delete it #########\n",
    "    for cluster_idx in cluster_dict_1:\n",
    "        cluster_dict_1[cluster_idx] = np.array(cluster_dict_1[cluster_idx])\n",
    "\n",
    "    for cluster_idx in cluster_dict_2:\n",
    "        cluster_dict_2[cluster_idx] = np.array(cluster_dict_2[cluster_idx])\n",
    "    \n",
    "    #######################################################################\n",
    "\n",
    "    return roi, cluster_dict_1, cluster_dict_2\n",
    "    \n",
    "\n",
    "def inference_frame(inf_frame, mask_bound, hsv_color_1, hsv_color_2, cluster_dict_1, cluster_dict_2, roi, threshold=40, error_bound_1=(), error_bound_2=()):\n",
    "    x1, y1, x2, y2 = mask_bound\n",
    "    inf_roi = inf_frame[y1:y2, x1:x2]\n",
    "    inf_roi_hsv = cv2.cvtColor(inf_roi, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # black\n",
    "    mask_1 = apply_threshold_hsv(inf_roi_hsv, hsv_color_1, threshold)\n",
    "    inf_roi[mask_1 != 0] = [255, 0, 0]\n",
    "\n",
    "    # white\n",
    "    mask_2 = apply_threshold_hsv(inf_roi_hsv, hsv_color_2, threshold)\n",
    "    inf_roi[mask_2 != 0] = [255, 0, 255]\n",
    "\n",
    "    black_error_keys = filter_keys(cluster_dict_1, roi, inf_roi, error_bound_1)\n",
    "    white_error_keys = filter_keys(cluster_dict_2, roi, inf_roi, error_bound_2)\n",
    "\n",
    "    return inf_roi, black_error_keys, white_error_keys\n",
    "    \n",
    "\n",
    "white_keys = ['C', 'D', 'E', 'F', 'G', 'A', 'B']\n",
    "black_keys = ['C#', 'D#', 'F#', 'G#', 'A#']\n",
    "\n",
    "def encode_to_scale(values, scale):\n",
    "    encoded_notes = []\n",
    "    scale_length = len(scale)\n",
    "    for value in values:\n",
    "        # Map each value to a note in the scale\n",
    "        note = scale[value % scale_length]\n",
    "        encoded_notes.append(note)\n",
    "    return encoded_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1b3c8b17-a5c7-4fac-9dda-ff3af69a3461",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap =  cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "ref_img = False\n",
    "# white = (196, 140, 233)\n",
    "# black = (161, 222, 216)\n",
    "HSV_color_1 = (174, 131, 201)\n",
    "HSV_color_2 = (29, 58, 201)\n",
    "\n",
    "while cap.isOpened():\n",
    "    \n",
    "    success, frame_img = cap.read()\n",
    "\n",
    "    if not success:\n",
    "        print(\"Ignoring empty camera frame.\")\n",
    "        break\n",
    "\n",
    "    if not ref_img:    \n",
    "        cv2.imshow('Pressed Key Frame', frame_img)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('s'):\n",
    "            mask_bound = (0, 265, 640, 452)\n",
    "            roi, cluster_dict_1, cluster_dict_2 = reference_frame(frame_img, mask_bound, HSV_color_1 , HSV_color_2)\n",
    "            ref_img = True\n",
    "            black_error_bounds, white_error_bounds = generate_error_bounds_for_clusters(cluster_dict_1, cluster_dict_2, initial_threshold=8)\n",
    "\n",
    "    elif(ref_img):\n",
    "        frame_roi, black_error_keys, white_error_keys = inference_frame(frame_img, mask_bound, HSV_color_1, HSV_color_2,\n",
    "                cluster_dict_1, cluster_dict_2, roi, threshold=40, \n",
    "                error_bound_1=black_error_bounds, error_bound_2=white_error_bounds)\n",
    "        \n",
    "        encoded_notes_black = encode_to_scale(black_error_keys, black_keys)\n",
    "        encoded_notes_white = encode_to_scale(white_error_keys, white_keys)\n",
    "        all_notes = encoded_notes_white + encoded_notes_black\n",
    "        \n",
    "        if(all_notes):\n",
    "            # print(all_notes)\n",
    "            pass\n",
    "\n",
    "        for keys in black_error_keys:\n",
    "            for i in cluster_dict_1[keys]:\n",
    "                rows, columns = i\n",
    "                \n",
    "                frame_roi[rows][columns][0] = 0\n",
    "                frame_roi[rows][columns][1] = 255\n",
    "                frame_roi[rows][columns][2] = 0\n",
    "                \n",
    "        for keys in white_error_keys:\n",
    "            for i in cluster_dict_2[keys]:\n",
    "                rows, columns = i\n",
    "                \n",
    "                frame_roi[rows][columns][0] = 0\n",
    "                frame_roi[rows][columns][1] = 125\n",
    "                frame_roi[rows][columns][2] = 125\n",
    "        \n",
    "        cv2.imshow('Pressed Key Frame', frame_roi)\n",
    "\n",
    "    cv2.waitKey(1)\n",
    "    if cv2.getWindowProperty('Pressed Key Frame', cv2.WND_PROP_VISIBLE) < 1:\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fb9c1d-190f-48ab-a67a-fbc7a8b3242e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9b7ae9-484f-42ce-9808-00ba1e902004",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "180DA",
   "language": "python",
   "name": "180da"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
